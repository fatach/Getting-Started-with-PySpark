{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fatach/Getting-Started-with-PySpark/blob/main/Getting_Started_with_PySpark.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G8YJkS4_5eXL",
        "outputId": "e9d0f45e-76ab-40ed-e0cb-ed7a45611c62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.3.1.tar.gz (281.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.4/281.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting py4j==0.10.9.5\n",
            "  Downloading py4j-0.10.9.5-py2.py3-none-any.whl (199 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.7/199.7 KB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.3.1-py2.py3-none-any.whl size=281845512 sha256=57e1b46ec2f4b4f1714446d38dd77a6ea0916bacaa01c1a10beae4e386f9b5cc\n",
            "  Stored in directory: /root/.cache/pip/wheels/43/dc/11/ec201cd671da62fa9c5cc77078235e40722170ceba231d7598\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9.5 pyspark-3.3.1\n"
          ]
        }
      ],
      "source": [
        "# install Pyspark\n",
        "#!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Z5fiL2b-VKL"
      },
      "outputs": [],
      "source": [
        "# Initialize spark session\n",
        "from pyspark.sql import SparkSession\n",
        "sc = SparkSession.builder.appName(\"Colab\").getOrCreate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc4p1wCaDm6v",
        "outputId": "35f197b6-8c09-4ec9-f5a3-1681d9723b43"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 4, 9, 16, 25]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "my_list = [1, 2, 3, 4, 5]\n",
        "squared_my_list= list(map(lambda x:x*x ,my_list))\n",
        "squared_my_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBFUQRiNEDmn",
        "outputId": "a9610afd-662b-49b6-ed18-b77615ab0e83"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[1, 3, 5]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "filtered_my_list= list(filter(lambda x:(x%2 !=0 ), my_list))\n",
        "filtered_my_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dcujnkxDJAb"
      },
      "outputs": [],
      "source": [
        "# Creating RDD from Object\n",
        "nb= list(range(0,100))\n",
        "\n",
        "#load number into spark\n",
        "nbRDD= spark.sparkContext.parallelize(nb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nWMg1e5bDI8F",
        "outputId": "2f851f96-4fbe-4311-fdaa-e5d9a1f8d6e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "pyspark.rdd.RDD"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(nbRDD)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR8wg_FwDI0C",
        "outputId": "4901d08f-751a-4397-f8f4-80d3c66d2381"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n",
            "8\n",
            "27\n",
            "64\n",
            "125\n"
          ]
        }
      ],
      "source": [
        "# map transformation\n",
        "nbRDD= spark.sparkContext.parallelize(my_list)\n",
        "cubeRDD= nbRDD.map(lambda x:x**3)\n",
        "nb_all = cubeRDD.collect()\n",
        "[print (num) for num in nb_all];"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbOpZJP2UPbK"
      },
      "source": [
        "FONCTION  **MAP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxieXayDT8jY"
      },
      "outputs": [],
      "source": [
        " #map applies a function to every element of an RDD and returns a new RDD\n",
        " # with the function applied to each element independently,"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYN8rQ-CDIwq",
        "outputId": "e3b51065-a853-414a-9a64-f9038f1a079d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 4, 6, 8]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Create an RDD from a list\n",
        "rdd = sc.sparkContext.parallelize([1, 2, 3, 4])\n",
        "# Define the function to be applied to each element\n",
        "def square(x):\n",
        "    return x*2\n",
        "# Apply the map operation\n",
        "squared_rdd = rdd.map(square)\n",
        "print(squared_rdd.collect())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUh78pDzUWyc"
      },
      "source": [
        "FONCTIOn **REDUCE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o5bMIm7eUB6v"
      },
      "outputs": [],
      "source": [
        "# reduce takes all elements of an RDD and applies a binary operator \n",
        "#cumulatively to them to reduce the collection to a single value."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5fHRk5KStdt",
        "outputId": "3d60f189-5f6a-4a1b-fce0-6bc1c8676295"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "36\n"
          ]
        }
      ],
      "source": [
        "# Create an RDD from a list\n",
        "li= [1, 2, 3, 6]\n",
        "rdd = sc.sparkContext.parallelize(li)\n",
        "# Apply the reduce operation\n",
        "tt = rdd.reduce(lambda a, b: a * b)\n",
        "\n",
        "# Print the result\n",
        "print(tt)\n",
        "# Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYoVaTsBUcEj"
      },
      "source": [
        "Fonction **FiLTER**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXbHsSU7StPo"
      },
      "outputs": [],
      "source": [
        "# The filter operation returns a new RDD that contains only \n",
        "#the elements that satisfy a certain condition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYmE9_-pStDG",
        "outputId": "11e6aeaa-5088-467d-d77d-187a91d9a5db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[3]\n"
          ]
        }
      ],
      "source": [
        "# Create an RDD from a list\n",
        "rdd = sc.sparkContext.parallelize([1, -2, 3, -4])\n",
        "# Define the filter function\n",
        "def greater_than_two(x):\n",
        "    return x > 2\n",
        "\n",
        "# Apply the filter operation\n",
        "filtered_rdd = rdd.filter(greater_than_two)\n",
        "\n",
        "# Collect the results\n",
        "print(filtered_rdd.collect())\n",
        "# Output:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CawPDwnsV6ra"
      },
      "source": [
        "Fonction **GROUPBYKEY**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bOvcOyaTV-tE"
      },
      "outputs": [],
      "source": [
        "#The groupByKey operation groups the elements of an RDD by key and \n",
        "#returns a new RDD of pairs where the first element is the key and\n",
        "# the second element is an iterator over the values for that key. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMvwv0k8V_kR",
        "outputId": "5f6ad91a-4808-4102-ba36-890c9d36b9dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[(1, ['a', 'd']), (2, ['b', 'e']), (3, ['c'])]\n"
          ]
        }
      ],
      "source": [
        "# Create an RDD from a list of pairs\n",
        "rdd = sc.sparkContext.parallelize([(1, \"a\"), (2, \"b\"), (3, \"c\"), (1, \"d\"), (2, \"e\")])\n",
        "\n",
        "# Apply the groupByKey operation\n",
        "grouped_rdd = rdd.groupByKey().mapValues(list)\n",
        "\n",
        "# Collect the results\n",
        "print(grouped_rdd.collect())\n",
        "# Output: [(1, ['a', 'd']), (2, ['b', 'e']), (3, ['c'])]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4NptAxvXBZC"
      },
      "source": [
        "Fonction **COUNT**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxRkqtewXYCd"
      },
      "outputs": [],
      "source": [
        "# count : The count operation returns the number of elements in the RDD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkbPVivNX8Yh",
        "outputId": "1b76bd7f-9825-4b59-c3c3-addd4b696796"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "7\n"
          ]
        }
      ],
      "source": [
        "# Create an RDD from a list\n",
        "rdd = sc.sparkContext.parallelize([1, 2, 3, 4, 10, 8, 8])\n",
        "\n",
        "# Apply the count operation\n",
        "count = rdd.count()\n",
        "\n",
        "# Print the result\n",
        "print(count)\n",
        "# Output: 4\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qib8YaZJXERX"
      },
      "source": [
        "Fonction **FIRST**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s0CygwJ0XbAy"
      },
      "outputs": [],
      "source": [
        "#  first : The first operation returns the first element in the RDD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7LFBesuCZ0dk",
        "outputId": "f5f138e6-091e-491b-b148-9f7b16ec103a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "# Create an RDD from a list\n",
        "rdd = sc.sparkContext.parallelize([1, 2, 3, 4])\n",
        "\n",
        "# Apply the first operation\n",
        "first = rdd.first()\n",
        "\n",
        "# Print the result\n",
        "print(first)\n",
        "# Output: 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33pJCuPTXJUB"
      },
      "source": [
        "FOnction COLLECT()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "imI0dGHnXfnx"
      },
      "outputs": [],
      "source": [
        "#collect : The collect operation returns all the elements of the RDD as an array."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KPdFzyQEaAJy",
        "outputId": "860af655-c450-4fc6-8efc-983edc0672ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 5, 75, 2, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "# Create an RDD from a list\n",
        "rdd = sc.sparkContext.parallelize([1,5, 75, 2, 3, 4])\n",
        "\n",
        "# Apply the collect operation\n",
        "result = rdd.collect()\n",
        "\n",
        "# Print the result\n",
        "print(result)\n",
        "# Output: [1, 2, 3, 4]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cNy3X-kXMi8"
      },
      "source": [
        "Fonction **CountByKey**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKVAYS6dXsVJ"
      },
      "outputs": [],
      "source": [
        "  #countByKey : The countByKey operation returns a dictionary that contains the count of elements for each key in the RDD."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ddLMUvkaP5o",
        "outputId": "0bd12824-35d9-4746-e3bb-31b28a6ecb3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "defaultdict(<class 'int'>, {1: 2, 2: 3, 3: 1, 4: 1, 5: 1})\n"
          ]
        }
      ],
      "source": [
        "# Create an RDD from a list of pairs\n",
        "rdd = sc.sparkContext.parallelize([(1, \"a\"), (2, \"b\"), (3, \"c\"), (1, \"d\"), (2, \"g\"),(4, \"o\"),(5, \"b\"),(2, \"b\")])\n",
        "\n",
        "# Apply the countByKey operation\n",
        "countByKey = rdd.countByKey()\n",
        "\n",
        "# Print the result\n",
        "print(countByKey)\n",
        "# Output: {1: 2, 2: 2, 3: 1}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuCkXH1qXSkU"
      },
      "source": [
        "Fonction **Foreach**\n",
        "\n",
        "---\n",
        "\n",
        "*foreach* : The foreach operation applies a function to each element of the RDD.\n",
        "It is typically used for actions such as printing or storing the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cc_i2WTjaunj"
      },
      "outputs": [],
      "source": [
        "# Create an RDD from a list\n",
        "rdd = sc.sparkContext.parallelize([1, 2, 3, 4])\n",
        "\n",
        "# Define the function to be applied\n",
        "def print_elem(x):\n",
        "    print(x)\n",
        "\n",
        "# Apply the foreach operation\n",
        "rdd.foreach(print_elem)\n",
        "\n",
        "# Output:\n",
        "\n",
        "\"\"\"\n",
        "foreach performs an operation or an action on the elements of the RDD, the operation \n",
        "is applied to every element in the RDD, but it doesn't return a result.\n",
        "It is typically used for side effects such as storing the data or printing the data.\n",
        "\n",
        "For example, you can use foreach to insert data into a database, send data to a message queue, or write data to a file.\n",
        "rdd.foreach(lambda x: insert_to_db(x))  #insert to database\n",
        "rdd.foreach(lambda x: send_to_kafka(x))  #send data to kafka\n",
        "rdd.foreach(lambda x: write_to_file(x)) #write data to a file\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bsdtqbEX2Sx"
      },
      "source": [
        "Fonction **Distinct**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wui9-BeNW9VH"
      },
      "outputs": [],
      "source": [
        "#distinct : The distinct operation returns a new RDD that contain duplicate elements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZEqIWCs7d1B6",
        "outputId": "a28bdfec-b2b0-4f77-ba17-581d94742a0d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4]\n"
          ]
        }
      ],
      "source": [
        "# Create an RDD from a list\n",
        "rdd = sc.sparkContext.parallelize([1, 2, 3, 2, 4, 1])\n",
        "\n",
        "# Apply the distinct operation\n",
        "distinct_rdd = rdd.distinct()\n",
        "\n",
        "# Collect the results\n",
        "print(distinct_rdd.collect())\n",
        "# Output: [1, 2, 3, 4]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VuonJj1-k1I_"
      },
      "source": [
        "# **Loading data into PySpark**\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "In PySpark we deal with large-scale datasets. So it’s an important task to load data for data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTcEIxqWlB0r"
      },
      "outputs": [],
      "source": [
        "df = sc.read.csv('people.csv', header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CxG6TZBPnbdt",
        "outputId": "cb557377-cc23-4917-f68c-6bb1148c0935"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+---------+-----------------+------+-------------+\n",
            "|_c0|person_id|             name|   sex|date of birth|\n",
            "+---+---------+-----------------+------+-------------+\n",
            "|  0|      100|   Penelope Lewis|female|   1990-08-31|\n",
            "|  1|      101|    David Anthony|  male|   1971-10-14|\n",
            "|  2|      102|        Ida Shipp|female|   1962-05-24|\n",
            "|  3|      103|     Joanna Moore|female|   2017-03-10|\n",
            "|  4|      104|   Lisandra Ortiz|female|   2020-08-05|\n",
            "|  5|      105|    David Simmons|  male|   1999-12-30|\n",
            "|  6|      106|    Edward Hudson|  male|   1983-05-09|\n",
            "|  7|      107|     Albert Jones|  male|   1990-09-13|\n",
            "|  8|      108| Leonard Cavender|  male|   1958-08-08|\n",
            "|  9|      109|   Everett Vadala|  male|   2005-05-24|\n",
            "| 10|      110| Freddie Claridge|  male|   2002-05-07|\n",
            "| 11|      111|Annabelle Rosseau|female|   1989-07-13|\n",
            "| 12|      112|    Eulah Emanuel|female|   1976-01-19|\n",
            "| 13|      113|       Shaun Love|  male|   1970-05-26|\n",
            "| 14|      114|Alejandro Brennan|  male|   1980-12-22|\n",
            "| 15|      115|Robert Mcreynolds|  male|   1973-12-27|\n",
            "| 16|      116|   Carla Spickard|female|   1985-06-13|\n",
            "| 17|      117|Florence Eberhart|female|   2024-06-01|\n",
            "| 18|      118|     Tina Gaskins|female|   1966-12-05|\n",
            "| 19|      119| Florence Mulhern|female|   1959-05-31|\n",
            "+---+---------+-----------------+------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYByy9Hunokh",
        "outputId": "666bf45e-b53b-4f97-e818-8ed9af73e22b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "150752"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_d10VGvWoLsM",
        "outputId": "2dea5c73-ffef-4c32-86a8-6bb65f349852"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['_c0', 'person_id', 'name', 'sex', 'date of birth']"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FxeqDQW0o0QZ",
        "outputId": "df7ec819-9b94-4320-c663-2ad89515fc84"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DataFrame[summary: string, _c0: string, person_id: string, name: string, sex: string, date of birth: string]"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxTA_3vopEDo",
        "outputId": "ccd130df-c7cd-4878-ff47-85a459106d3d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---+---------+----------------+------+-------------+\n",
            "|_c0|person_id|            name|   sex|date of birth|\n",
            "+---+---------+----------------+------+-------------+\n",
            "|  0|      100|  Penelope Lewis|female|   1990-08-31|\n",
            "|  1|      101|   David Anthony|  male|   1971-10-14|\n",
            "|  2|      102|       Ida Shipp|female|   1962-05-24|\n",
            "|  3|      103|    Joanna Moore|female|   2017-03-10|\n",
            "|  4|      104|  Lisandra Ortiz|female|   2020-08-05|\n",
            "|  5|      105|   David Simmons|  male|   1999-12-30|\n",
            "|  6|      106|   Edward Hudson|  male|   1983-05-09|\n",
            "|  7|      107|    Albert Jones|  male|   1990-09-13|\n",
            "|  8|      108|Leonard Cavender|  male|   1958-08-08|\n",
            "|  9|      109|  Everett Vadala|  male|   2005-05-24|\n",
            "+---+---------+----------------+------+-------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.show(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsLWO7iFpvk8",
        "outputId": "95bc73ee-cee6-493e-a116-eb26dfaa048e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------+-------------+\n",
            "|          name|date of birth|\n",
            "+--------------+-------------+\n",
            "|Penelope Lewis|   1990-08-31|\n",
            "| David Anthony|   1971-10-14|\n",
            "|     Ida Shipp|   1962-05-24|\n",
            "|  Joanna Moore|   2017-03-10|\n",
            "|Lisandra Ortiz|   2020-08-05|\n",
            "+--------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.select('name', 'date of birth').show(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfnpCCgQqbLI",
        "outputId": "4eb3ff0e-33fd-430e-fe8b-587d78dbde86"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- _c0: string (nullable = true)\n",
            " |-- person_id: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- sex: string (nullable = true)\n",
            " |-- date of birth: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfs0zlk0rfch"
      },
      "outputs": [],
      "source": [
        "df_drop_dupli= df.drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TaNC34kervqQ",
        "outputId": "c803f25c-a9b7-4bb5-fdaf-0e6c48424987"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before removing duplicates 150752\n",
            "After removing duplicates 100002\n"
          ]
        }
      ],
      "source": [
        "print('Before removing duplicates', df.count())\n",
        "print('After removing duplicates',df_drop_dupli.count())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS9kdscUs2VE",
        "outputId": "e315518a-9099-4894-91b5-7a097a44a23a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "100002"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df= df_drop_dupli\n",
        "df.count()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STRva6eysjyC"
      },
      "source": [
        "**filter out the rows based on a condition by using filter transformation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "anSxGkzFsQKo"
      },
      "outputs": [],
      "source": [
        "# by gender\n",
        "df_female= df.filter(df.sex == 'female')\n",
        "df_male = df.filter(df.sex == 'male')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jsukhDy6tXov",
        "outputId": "dfe082f6-bd6f-476e-cced-48e06e877a25"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-76-8f1e603a9e29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdf_male\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_famle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_famle' is not defined"
          ]
        }
      ],
      "source": [
        "df_male.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObIkcDfGxQxrGA/vIJaWgY",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}